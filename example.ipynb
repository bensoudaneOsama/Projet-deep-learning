{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example for clinical concept extraction with visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We highly recommend our [sentence segment tool](https://github.com/noc-lab/simple_sentence_segment) for detecting sentence boundary if the text contains arbitrary line breaks, such as the sample text in the following. To use this package, just run\n",
    "```\n",
    "pip install git+https://github.com/noc-lab/simple_sentence_segment.git\n",
    "```\n",
    "Alternatively, you can use the sentence segmentation tool in NLTK or Spacy. Also, you can use other tokenization tools than NLTK. But this example uses NTLK for the illustrative purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from spacy import displacy\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from simple_sentence_segment import sentence_segment\n",
    "from clinical_concept_extraction import clinical_concept_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of a discharge summary contains arbitrary line breaks. I faked this reports.\n",
    "sample_text = \"\"\"\n",
    "This is an 119 year old woman with a history of diabetes \n",
    "who has a CT-scan at 2020-20-20. Insulin is prescribed\n",
    "for the type-2 diabetes. Within the past year, the diabetic\n",
    "symptoms have progressively gotten worse.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    # Perform sentence segmentation, tokenization and return the lists of tokens,\n",
    "    # spans, and text for every sentence respectively\n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    all_sentences = []\n",
    "    all_spans = []\n",
    "    start = 0\n",
    "    normalized_text = ''\n",
    "    for span in sentence_segment(text):\n",
    "        sentence = sample_text[span[0]:span[1]]\n",
    "        sentence = re.sub('\\n', ' ', sentence)\n",
    "        sentence = re.sub(r'\\ +', ' ', sentence)\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        if len(sentence) > 0:\n",
    "            tokens_span = tokenizer.span_tokenize(sentence)\n",
    "            tokens = []\n",
    "            spans = []\n",
    "            for span in tokens_span:\n",
    "                tokens.append(sentence[span[0]:span[1]])\n",
    "                spans.append([start + span[0], start + span[1]])\n",
    "                \n",
    "            all_sentences.append(tokens)\n",
    "            all_spans.append(spans)\n",
    "            \n",
    "            start += len(sentence) + 1\n",
    "            normalized_text += sentence + '\\n'\n",
    "    return all_sentences, all_spans, normalized_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable tokenized_sentences contains token lists for every sentence:\n",
      "['This', 'is', 'an', '119', 'year', 'old', 'woman', 'with', 'a', 'history', 'of', 'diabetes', 'who', 'has', 'a', 'CT-scan', 'at', '2020-20-20', '.']\n",
      "['Insulin', 'is', 'prescribed', 'for', 'the', 'type-2', 'diabetes', '.']\n",
      "['Within', 'the', 'past', 'year', ',', 'the', 'diabetic', 'symptoms', 'have', 'progressively', 'gotten', 'worse', '.']\n",
      "\n",
      "Variable all_spans contains lists of token spans for every sentence:\n",
      "[[0, 4], [5, 7], [8, 10], [11, 14], [15, 19], [20, 23], [24, 29], [30, 34], [35, 36], [37, 44], [45, 47], [48, 56], [57, 60], [61, 64], [65, 66], [67, 74], [75, 77], [78, 88], [88, 89]]\n",
      "[[90, 97], [98, 100], [101, 111], [112, 115], [116, 119], [120, 126], [127, 135], [135, 136]]\n",
      "[[137, 143], [144, 147], [148, 152], [153, 157], [157, 158], [159, 162], [163, 171], [172, 180], [181, 185], [186, 199], [200, 206], [207, 212], [212, 213]]\n",
      "\n",
      "Variable normalized_text contains strings for every sentence concatented by line break:\n",
      "This is an 119 year old woman with a history of diabetes who has a CT-scan at 2020-20-20.\n",
      "Insulin is prescribed for the type-2 diabetes.\n",
      "Within the past year, the diabetic symptoms have progressively gotten worse.\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences, all_spans, normalized_text = parse_text(sample_text)\n",
    "\n",
    "print('Variable tokenized_sentences contains token lists for every sentence:')\n",
    "for tokens in tokenized_sentences:\n",
    "    print(tokens)\n",
    "    \n",
    "print('')\n",
    "print('Variable all_spans contains lists of token spans for every sentence:')\n",
    "for spans in all_spans:\n",
    "    print(spans)\n",
    "    \n",
    "print('')\n",
    "print('Variable normalized_text contains strings for every sentence concatented by line break:')\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function clinical_concept_extraction takes the lists of tokens as input and outputs the annotations\n",
    "all_annotations = clinical_concept_extraction(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          This O\n",
      "                            is O\n",
      "                            an O\n",
      "                           119 O\n",
      "                          year O\n",
      "                           old O\n",
      "                         woman O\n",
      "                          with O\n",
      "                             a O\n",
      "                       history O\n",
      "                            of O\n",
      "                      diabetes B-problem\n",
      "                           who O\n",
      "                           has O\n",
      "                             a B-test\n",
      "                       CT-scan I-test\n",
      "                            at O\n",
      "                    2020-20-20 O\n",
      "                             . O\n",
      "=============================================================\n",
      "                       Insulin B-treatment\n",
      "                            is O\n",
      "                    prescribed O\n",
      "                           for O\n",
      "                           the B-problem\n",
      "                        type-2 I-problem\n",
      "                      diabetes I-problem\n",
      "                             . O\n",
      "=============================================================\n",
      "                        Within O\n",
      "                           the O\n",
      "                          past O\n",
      "                          year O\n",
      "                             , O\n",
      "                           the B-problem\n",
      "                      diabetic I-problem\n",
      "                      symptoms I-problem\n",
      "                          have O\n",
      "                 progressively O\n",
      "                        gotten O\n",
      "                         worse O\n",
      "                             . O\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# see annotations for each tokens\n",
    "for sent_, ann_ in zip(tokenized_sentences, all_annotations):\n",
    "    for t, a in zip(sent_, ann_):\n",
    "        print('%30s %s' % (t, a))\n",
    "    print('='*61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_display_elements(tokens, annotations, spans):\n",
    "    # convert the annotations to the format used in displacy\n",
    "    all_ann = []\n",
    "\n",
    "    for sent_id, sent_info in enumerate(tokens):\n",
    "        sent_length = len(tokens[sent_id])\n",
    "\n",
    "        last_ann = 'O'\n",
    "        last_start = None\n",
    "        last_end = None\n",
    "        for token_id in range(sent_length):\n",
    "            this_ann = annotations[sent_id][token_id]\n",
    "\n",
    "            # separated cases:\n",
    "            if this_ann != last_ann:\n",
    "                if last_ann != 'O':\n",
    "                    # write last item\n",
    "                    new_ent = {}\n",
    "                    new_ent['start'] = last_start\n",
    "                    new_ent['end'] = last_end\n",
    "                    new_ent['label'] = last_ann[2:]\n",
    "                    all_ann.append(new_ent)\n",
    "\n",
    "                # record this instance\n",
    "                last_ann = 'O' if this_ann == 'O' else 'I' + this_ann[1:]\n",
    "                last_start = spans[sent_id][token_id][0]\n",
    "                last_end = spans[sent_id][token_id][1]\n",
    "\n",
    "            else:\n",
    "                last_ann = this_ann\n",
    "                last_end = spans[sent_id][token_id][1]\n",
    "\n",
    "        if last_ann != 'O':\n",
    "            new_ent = {}\n",
    "            new_ent['start'] = last_start\n",
    "            new_ent['end'] = last_end\n",
    "            new_ent['label'] = last_ann[2:]\n",
    "            all_ann.append(new_ent)\n",
    "\n",
    "    return all_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = build_display_elements(tokenized_sentences, all_annotations, all_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">This is an 119 year old woman with a history of \n",
       "<mark class=\"entity\" style=\"background: #fe4a49; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">problem</span>\n",
       "</mark>\n",
       " who has \n",
       "<mark class=\"entity\" style=\"background: #fed766; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    a CT-scan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">test</span>\n",
       "</mark>\n",
       " at 2020-20-20.</br>\n",
       "<mark class=\"entity\" style=\"background: #2ab7ca; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Insulin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">treatment</span>\n",
       "</mark>\n",
       " is prescribed for \n",
       "<mark class=\"entity\" style=\"background: #fe4a49; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the type-2 diabetes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">problem</span>\n",
       "</mark>\n",
       ".</br>Within the past year, \n",
       "<mark class=\"entity\" style=\"background: #fe4a49; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the diabetic symptoms\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">problem</span>\n",
       "</mark>\n",
       " have progressively gotten worse.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ent_inp = {\n",
    "    'text': normalized_text,\n",
    "    'ents': ent,\n",
    "    'title': ''\n",
    "}\n",
    "\n",
    "colors = {'PROBLEM': '#fe4a49', 'TEST': '#fed766', 'TREATMENT': '#2ab7ca'}\n",
    "options = {'colors': colors}\n",
    "\n",
    "html = displacy.render(ent_inp, style='ent', manual=True, options=options)\n",
    "display(HTML(html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
